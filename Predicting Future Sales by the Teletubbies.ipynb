{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Future Sales by the Teletubbies"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, we are looking to **predict future sales** for every store using historical data.\n\n----\n\nMission brief:\n*\"You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\"*"},{"metadata":{},"cell_type":"markdown","source":"To make our predictions, we will follow the OSEMN data science framework\n1. **O**btain the data \n    * Load the prerequisite packages\n    * Load the data\n2. **S**crub the data\n    * Identify data oddities\n    * Identify missing values\n3. **E**xplore the data\n    * Examine the nature of the variables\n    * Explore the time series data\n    * Conduct feature engineering\n4. **M**odel the data \n    * Create the model\n    * Fine-tune the model\n5. I**n**terpret the data"},{"metadata":{},"cell_type":"markdown","source":"## Step \\#1: Obtain the data"},{"metadata":{},"cell_type":"markdown","source":"### Load the prerequisite packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard data science packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Data visualisation packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check what files are in the input directory\nimport os\nprint(os.listdir(\"../input/competitive-data-science-predict-future-sales\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the data\nraw_sales = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nraw_items = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nraw_shops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\nraw_test = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\nraw_sample = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nraw_item_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Do some initial exploration of the data"},{"metadata":{},"cell_type":"markdown","source":"#### Sales data"},{"metadata":{},"cell_type":"markdown","source":"The training dataset contains a row for each item-shop combination by day and provides the items sold per day (item_cnt_day). Some questions to be validated:\n- Is this unique by date x shop ID x item ID combination?\n- Why are some values for item_cnt_day negative? Are these refunds?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales  = raw_sales.copy()\ndf_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Submission data"},{"metadata":{},"cell_type":"markdown","source":"The submission format is to provide item_cnt_month for each ID.\n\nTo be validated:\n* What ID is this?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ssubmission = raw_sample.copy()\ndf_ssubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = raw_test.copy()\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step \\#2: Scrub the data "},{"metadata":{},"cell_type":"markdown","source":"### Join the reference data to the sales data"},{"metadata":{},"cell_type":"markdown","source":"#### First join: shop data\n\nWe will join the shop data to the sales data. We will perform a left join and we will check that there are no duplicated rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_shops = raw_shops.copy(deep = True)\nprint(\"Dataframe size: \", df_shops.shape)\ndf_shops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales2 = pd.merge(left = df_sales, right = df_shops, on = 'shop_id')\nprint(\"Pre-join row count:\", len(df_sales.index))\nprint(\"Post-join row count:\", len(df_sales2.index))\nif len(df_sales.index) == len(df_sales2.index):\n    print(\"You're safe - no row duplication found!\")\nelse: \n    print(\"WARNING: Rows have been duplicated!\")\ndf_sales2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Next set of joins: item and item categories data\n\nNext, we will add the item names and item categories to the sales data "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_items = raw_items.copy(deep = True)\nprint(\"Dataframe size: \", df_items.shape)\ndf_items.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_item_categories = raw_item_categories.copy(deep = True)\nprint(\"Dataframe size: \", df_item_categories.shape)\ndf_item_categories.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_items2 = pd.merge(left = df_items, right = df_item_categories, on = 'item_category_id')\nprint(\"Pre-join row count:\", len(df_items.index))\nprint(\"Post-join row count:\", len(df_items2.index))\nif len(df_items.index) == len(df_items2.index):\n    print(\"You're safe - no row duplication found!\")\nelse: \n    print(\"WARNING: Rows have been duplicated!\")\ndf_items2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales3 = pd.merge(left = df_sales2, right = df_items2, on = 'item_id')\nprint(\"Pre-join row count:\", len(df_sales2.index))\nprint(\"Post-join row count:\", len(df_sales3.index))\nif len(df_sales2.index) == len(df_sales3.index):\n    print(\"You're safe - no row duplication found!\")\nelse: \n    print(\"WARNING: Rows have been duplicated!\")\ndf_sales3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Check for oddities in the data\n-------\n\n#### Findings\n* ~75% of the rows have 1 in the item_cnt_day column\n* The minimum value in item_cnt_day column is -2.2\n* The highest value in item_cnt_day column is 2,169"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_sales3.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot = df_sales3.boxplot(column ='item_cnt_day')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for missing values\n\n---\n\n#### Findings\n* There are no missing values in the cells"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check if there are any NaNs in the data by converting all sales to Booleans and seeing if any are 1\ndf_sales3.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step \\#3: Explore the data"},{"metadata":{},"cell_type":"markdown","source":"### Examine the variables\n\nWe should explore the nature of the static data such as the number of products by item category and by store."},{"metadata":{},"cell_type":"markdown","source":"#### How many items exist within each item category?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group the items df by the item category id\nitems_per_cat = df_items2.groupby(['item_category_id']).count()\n\n# Sort the item categories by the number of items in them in descending order\nitems_per_cat = items_per_cat.sort_values(by = 'item_id', ascending = False)\n\n# Filter only the top 10 item categories\nitems_per_cat = items_per_cat.iloc[0:20].reset_index()\nitems_per_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nax = sns.barplot(data = items_per_cat, x = 'item_category_id', y = 'item_id', color = \"mediumblue\", order = items_per_cat.item_category_id)\nplt.title(\"The number of items in the top 10 largest item categories\")\nplt.ylabel(\"Number of item IDs\")\nplt.xlabel(\"Item category ID\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explore the time series data\n\nAs this is sales data, we should examine how it varies over time and how it varies by product."},{"metadata":{},"cell_type":"markdown","source":"# KYY model playground"},{"metadata":{"trusted":true},"cell_type":"code","source":"kyy_raw_data = df_sales3.copy()\nkyy_raw_data['year']=pd.DatetimeIndex(kyy_raw_data['date']).year\nkyy_raw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kyy_data_test = kyy_raw_data[['shop_id', 'item_id', 'item_cnt_day', 'item_price', 'year']]\nkyy_data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kyy_data_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kyy_data_test2 =kyy_data_test.astype({\"shop_id\": 'category' , \"item_id\": 'category', 'item_cnt_day': int, 'item_price': float, 'year':int})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = kyy_data_test2[['shop_id', 'item_id','item_price','year']]\ny = kyy_data_test2[['item_cnt_day']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport seaborn as seabornInstance \nregressor_kyy = LinearRegression()  \nregressor_kyy.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_df = pd.DataFrame(regressor_kyy.coef_, X.columns, columns=['Coefficient'])  \ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor_kyy.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred_kyy = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf_pred_kyy1 = df_pred_kyy.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}